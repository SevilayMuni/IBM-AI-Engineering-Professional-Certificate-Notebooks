{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Preparation with PyTorch</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Crack detection has vital importance for structural health monitoring and inspection. We will train neural network to detect Cracks, images that contain cracks will be denoted as positive and images with no cracks as negative. In this notebook, we will build a dataset object. There are five questions in this notebook, Including some questions that are intermediate steps to help us build the dataset object. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports and Auxiliary Functions \n",
    "2. Download Data\n",
    "3. Examine Files\n",
    "4. Question 1: find number of files\n",
    "5. Assign Labels to Images\n",
    "6. Question 2: Assign labels to image\n",
    "7. Training  and Validation  Split\n",
    "8. Question 3: Training  and Validation  Split\n",
    "9. Create a Dataset Class\n",
    "10. Question 4: Display  training dataset object\n",
    "11. Question 5: Display  validation dataset object\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import skillsnetwork "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to plot\n",
    "\n",
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap = 'gray')\n",
    "    plt.title('y = ' + data_sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. <b>skillsnetwork.prepare</b> is a command that's used to download a zip file, unzip it and store it in a specified directory. Locally we store the data in the directory  **/resources/data**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\",\n",
    "                            path = \"/resources/data\", overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"examine_files\">Examine Files </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we created two lists; one to hold the path to the Negative files and one to hold the path to the Positive files. This process is shown in the following few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain the list that contains the path to the negative files\n",
    "\n",
    "directory = \"/resources/data\"\n",
    "negative = 'Negative'\n",
    "negative_file_path = os.path.join(directory, negative)\n",
    "negative_files = [os.path.join(negative_file_path, file)\n",
    "                  for file in os.listdir(negative_file_path)\n",
    "                  if file.endswith('.jpg')]\n",
    "negative_files.sort()\n",
    "\n",
    "# Show first three path names\n",
    "negative_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain the list that contains the path to the positive files\n",
    "\n",
    "positive = 'Positive'\n",
    "positive_file_path = os.path.join(directory, positive)\n",
    "positive_files = [os.path.join(positive_file_path, file)\n",
    "                  for file in os.listdir(positive_file_path)\n",
    "                  if file.endswith('.jpg')]\n",
    "positive_files.sort()\n",
    "\n",
    "# Show first three path names\n",
    "positive_files[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n",
    "<b>Find the <b>combined</b> length of the list <code>positive_files</code> and <code>negative_files</code> using the function <code>len</code> . Then assign  it to the variable <code>number_of_samples</code></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_samples = len(positive_files) + len(negative_files)\n",
    "number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"assign_labels\">Assign Labels to Images </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will assign a label to each image in this case we  can assign the positive images, i.e images with a crack to a value one  and the negative images i.e images without a crack to a value of zero <b>Y</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create tensor or vector of zeros, each element corresponds to new sample\n",
    "# Tensor length = number of samples\n",
    "\n",
    "Y = torch.zeros([number_of_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using the tensor <b>Y</b> for classification we cast it to a <code>LongTensor</code>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cast Y to LongTensor\n",
    "\n",
    "Y = Y.type(torch.LongTensor)\n",
    "Y.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to each element we will set the even elements to class one and the odd elements to class zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y[::2] = 1\n",
    "Y[1::2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2</h2>\n",
    "<b>Create a list all_files such that the even indexes contain the path to images with positive or cracked samples and the odd element contain the negative images or images without cracks.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = [None]*number_of_samples\n",
    "all_files[::2] = positive_files\n",
    "all_files[1::2] = negative_files\n",
    "all_files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print testing samples\n",
    "\n",
    "for y, file in zip(Y, all_files[0:4]):\n",
    "    plt.imshow(Image.open(file))\n",
    "    plt.title('y = ' + str(y.item()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"split\">Training  and Validation  Split  </h2>\n",
    "When training the model we  split up our data into training and validation data. If the variable train is set to <code>True</code>  the following lines of code will segment the  tensor <b>Y</b> such at  the first 30000 samples are used for training. If the variable train is set to <code>False</code> the remainder of the samples will be used for validation data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "if train:\n",
    "    all_files = all_files[0:30000]\n",
    "    Y = Y[0:30000]\n",
    "\n",
    "else:\n",
    "    all_files = all_files[30000:]\n",
    "    Y = Y[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3</h2>\n",
    "Modify the above lines of code such that if the variable <code>train</code> is set to <c>True</c> the first 30000 samples of all_files are use in training. If <code>train</code> is set to <code>False</code> the remaining  samples are used for validation. In both cases reassign  the values to the variable all_files, then use the following lines of code to print out the first four validation sample images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split(train):\n",
    "\n",
    "    Y = torch.zeros([number_of_samples])\n",
    "    Y = Y.type(torch.LongTensor)\n",
    "    Y[::2] = 1\n",
    "    Y[1::2] = 0\n",
    "    \n",
    "    all_files = [None]*(number_of_samples)\n",
    "    all_files[::2] = positive_files\n",
    "    all_files[1::2] = negative_files\n",
    "\n",
    "    if train:\n",
    "        all_files = all_files[0:30000]\n",
    "        Y = Y[0:30000]\n",
    "\n",
    "    else:\n",
    "        all_files = all_files[30000:]\n",
    "        Y = Y[30000:]\n",
    "        \n",
    "    return all_files, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Acquire validation dataset\n",
    "all_files, Y = split(train = False)\n",
    "\n",
    "# Print first four validation samples\n",
    "for y, file in zip(Y, all_files[0:4]):\n",
    "    plt.imshow(Image.open(file))\n",
    "    plt.title('y = ' + str(y.item()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Create a Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the previous code to build a dataset class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Complete the code to build a Dataset class <code>dataset</code>. As before, make sure the even samples are positive, and the odd samples are negative.  If the parameter <code>train</code> is set to <code>True</code>, use the first 30 000  samples as training data; otherwise, the remaining samples will be used as validation data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a Dataset class dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, transform = None, train = True):\n",
    "        directory = '/resources/data'\n",
    "        positive = 'Positive'\n",
    "        negative = 'Negative'\n",
    "\n",
    "        positive_file_path = os.path.join(directory, positive)\n",
    "        negative_file_path = os.path.join(directory, negative)\n",
    "        \n",
    "        positive_files = [os.path.join(positive_file_path, file) for file\n",
    "                          in os.listdir(positive_file_path) if file.endswith('.jpg')]\n",
    "        positive_files.sort()\n",
    "        \n",
    "        negative_files = [os.path.join(negative_file_path, file) for file\n",
    "                          in os.listdir(negative_file_path) if file.endswith('.jpg')]\n",
    "        negative_files.sort()\n",
    "\n",
    "        self.all_files = [None]*number_of_samples\n",
    "        self.all_files[::2] = positive_files # Even samples are positive\n",
    "        self.all_files[1::2] = negative_files # Odd samples are negative\n",
    "        \n",
    "        # Transform will be used on image\n",
    "        self.transform = transform\n",
    "        \n",
    "        # torch.LongTensor\n",
    "        self.Y = torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2] = 1\n",
    "        self.Y[1::2] = 0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files = self.all_files[0:30000]\n",
    "            self.Y = self.Y[0:30000]\n",
    "            self.len = len(self.all_files)\n",
    "        else:\n",
    "            self.all_files = self.all_files[30000:]\n",
    "            self.Y = self.Y[30000:]\n",
    "            self.len = len(self.all_files)\n",
    "\n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.all_files[idx])\n",
    "        y = self.Y[idx]\n",
    "\n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_4\">Question 4</h2>\n",
    "<b>Create a Dataset object <code>dataset</code> for the training data, use the following lines of code to print out sample the 10th and  sample 100 (remember zero indexing)  </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dset = Dataset(train = True) # Creating Dataset object\n",
    "samples = [9, 99] # 10th and 100th samples\n",
    "\n",
    "for sample in samples:\n",
    "    plt.imshow(training_dset[sample][0])\n",
    "    plt.xlabel('y = ' + str(training_dset[sample][1].item()))\n",
    "    plt.title('Training data; sample {}'.format(int(sample)+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_5\">Question 5</h2>\n",
    "<b>Create a Dataset object <code>dataset</code> for the validation  data, use the following lines of code to print out the 16 th and  sample 103 (remember zero indexing)   </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dset = Dataset(train = False) # Creating Dataset object for the validation data\n",
    "samples = [15, 102] # 15th and 103 th samples\n",
    "\n",
    "for sample in samples:\n",
    "    plt.imshow(validation_dset[sample][0])\n",
    "    plt.xlabel('y = ' + str(validation_dset[sample][1].item()))\n",
    "    plt.title('Validation data; sample {}'.format(int(sample)+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright Â© 2018 Cognitive Class. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
